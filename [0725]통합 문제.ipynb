{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[0725]통합 문제.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1번 문제\n","\n","* Kaggle 사이트의 Biomechanical features of orthopedic patients 데이터 세트입니다. 데이터의 feature들 사이의 관계, 각각의 특징을 파악하여 두개의 feature를 조합해 보세요. \n","* 강의에서 배운 지도학습 모델들을 모두 적용한 코드가 작성되어있습니다. 각 모델의 정확도를 비교하고 두개의 모델을 선택하여 파라미터를 조정하고 가장 높은 정확도를 도출하는 파라미터 조합을 찾으세요.\n"],"metadata":{"id":"_gUDvDiwxJnv"}},{"cell_type":"markdown","source":["# Biomechanical features of orthopedic patients dataset\n","\n","**Content**\n","\n","각 환자는 골반과 요추의 모양과 방향에서 도출된 6가지 생체역학적 속성으로 데이터 세트에 표현됨.(each one is a column):\n","\n","* pelvic incidence\n","* pelvic tilt\n","* lumbar lordosis angle\n","* sacral slope\n","* pelvic radius\n","* grade of spondylolisthesis\n","\n","**Inspiration**\n","\n","이러한 생체역학 features를 사용하여 label에 따라 환자를 분류할 수 있음."],"metadata":{"id":"v8EmAQZxs0H2"}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"1_HQNASNXuNt"}},{"cell_type":"code","source":["# common lib\n","import sklearn\n","import numpy as np"],"metadata":{"id":"-guJ4B_vYAxV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dataset"],"metadata":{"id":"XOMC9w0tOd9V"}},{"cell_type":"markdown","source":["### read csv by pandas"],"metadata":{"id":"jk9pNKwdOmPD"}},{"cell_type":"markdown","source":["#### github"],"metadata":{"id":"KxFnoy4l4WDZ"}},{"cell_type":"code","source":["import pandas as pd\n","\n","url = 'https://raw.githubusercontent.com/EugeneYoo/practice_file/main/column_2C_weka.csv'\n","data = pd.read_csv(url, encoding='utf8')\n","data.head()"],"metadata":{"id":"Mq4lq8f64O4W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Data Visualization"],"metadata":{"id":"lr7BxoqPfWc8"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","sns.heatmap(data.corr(),annot=True)\n","plt.show()"],"metadata":{"id":"F9TU2lSVfc7Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.pairplot(data,hue=\"class\", palette='husl')\n","plt.show()"],"metadata":{"id":"JKrPIRzhfnHA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Preprocess"],"metadata":{"id":"A3KI9V8UPd1e"}},{"cell_type":"markdown","source":["### Split to data, target\n","\n"],"metadata":{"id":"M5wVTqWfPjxA"}},{"cell_type":"code","source":["target_name = 'class'\n","\n","patients_X = data.drop([target_name],axis = 1) \n","patients_y = data[target_name].values"],"metadata":{"id":"4YeVfHFZPpMv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Min, Max, Var, Std of features"],"metadata":{"id":"ji-wZ5daNvCs"}},{"cell_type":"code","source":["patients_X.max(axis=0)"],"metadata":{"id":"qYTmV8xbNzdR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["patients_X.min(axis=0)"],"metadata":{"id":"-ib6D0srOFpc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["patients_X.var(axis=0)"],"metadata":{"id":"UfinxXyCP4V2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Select feature and split"],"metadata":{"id":"eRNpVAFdjkub"}},{"cell_type":"markdown","source":["**<font color='red'>feature 두 개를 선택하시오.</font>**\n","* 조건\n","  1. Variance가 높은 feature 하나를 선택\n","  2. 선택된 feature와 상관 관계가 없는 feature 선택"],"metadata":{"id":"lCg0kKZp2H67"}},{"cell_type":"code","source":["print(patients_X.columns)\n","\n","features = ['{?}','{?}'] # you can choose features by their name\n","\n","patients_X_selected = patients_X[features]\n","\n","patients_X_selected = patients_X\n","\n","from sklearn.model_selection import train_test_split\n","patients_X_train, patients_X_test, patients_y_train, patients_y_test = train_test_split(patients_X_selected, patients_y, test_size=0.3, random_state=42)"],"metadata":{"id":"3SdTLoBKk3Ub"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Scaling \n"],"metadata":{"id":"mkJjKr93Btnt"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler_standard = StandardScaler()\n","patients_X_train_standard = scaler_standard.fit_transform(patients_X_train)\n","patients_X_test_standard = scaler_standard.transform(patients_X_test)\n","\n","from sklearn.preprocessing import RobustScaler\n","\n","scaler_robust = RobustScaler()\n","patients_X_train_robust = scaler_robust.fit_transform(patients_X_train)\n","patients_X_test_robust = scaler_robust.transform(patients_X_test)\n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler_minmax = MinMaxScaler()\n","patients_X_train_minmax = scaler_minmax.fit_transform(patients_X_train)\n","patients_X_test_minmax = scaler_minmax.transform(patients_X_test)"],"metadata":{"id":"eROl3Goc_Slz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JTjgtL1KHqrt"},"source":["## Accuracy for each model"]},{"cell_type":"markdown","source":["#### Visualization 함수"],"metadata":{"id":"-u5UeoKtbczO"}},{"cell_type":"code","source":["%matplotlib inline\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","def viz_val_bar(param_range, test_acc, param_name):\n","  idx = np.arange(len(param_range))\n","  colors = sns.color_palette('hls',len(param_range))\n","  bars = plt.bar(idx, test_acc, width=0.3, color=colors)\n","  plt.xlabel(param_name)\n","  plt.ylabel('Accuracy')\n","  plt.ylim([np.min(test_acc)*0.99, np.max(test_acc)*1.01])\n","  plt.legend(handles=bars, labels=param_range)\n","  plt.show()"],"metadata":{"id":"Twx6KcjzbfSx"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qJVJyBOuHqrt"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","clf1 = KNeighborsClassifier()\n","clf2 = GaussianNB()\n","clf3 = LogisticRegression()\n","clf4 = DecisionTreeClassifier(random_state=1)\n","clf5 = RandomForestClassifier(random_state=1)\n","\n","from sklearn.metrics import accuracy_score\n","\n","clfs = [clf1, clf2, clf3, clf4, clf5]\n","\n","raw_accs = []\n","class_names = []\n","for clf in clfs:\n","  clf.fit(patients_X_train, patients_y_train)\n","  pred = clf.predict(patients_X_test)\n","  class_name = clf.__class__.__name__\n","  class_names.append(class_name)\n","  raw_acc = accuracy_score(patients_y_test, pred)\n","  raw_accs.append(raw_acc)\n","\n","viz_val_bar(class_names, raw_accs, 'raw')\n","\n","print()\n","\n","standard_accs = []\n","for clf in clfs:\n","  clf.fit(patients_X_train_standard, patients_y_train)\n","  pred_standard = clf.predict(patients_X_test_standard)\n","  class_name = clf.__class__.__name__\n","  standard_acc = accuracy_score(patients_y_test, pred_standard)\n","  standard_accs.append(standard_acc)\n","viz_val_bar(class_names, standard_accs, 'standard')\n","\n","robust_accs = []\n","for clf in clfs:\n","  clf.fit(patients_X_train_robust, patients_y_train)\n","  pred_robust = clf.predict(patients_X_test_robust)\n","  class_name = clf.__class__.__name__\n","  robust_acc = accuracy_score(patients_y_test, pred_robust)\n","  robust_accs.append(robust_acc)\n","viz_val_bar(class_names, robust_accs,'robust')\n","\n","minmax_accs = []\n","for clf in clfs:\n","  clf.fit(patients_X_train_minmax, patients_y_train)\n","  pred_minmax = clf.predict(patients_X_test_minmax)\n","  class_name = clf.__class__.__name__\n","  minmax_acc = accuracy_score(patients_y_test, pred_minmax)\n","  minmax_accs.append(minmax_acc)\n","viz_val_bar(class_names, minmax_accs,'minmax')\n"]},{"cell_type":"markdown","source":["**<font color='red'>정확도가 높게 나타나는 모델 2개를 선택하고 스케일링 기법과 파라미터를 조정하여 더 높은 정확도를 도출하시오.</font>**"],"metadata":{"id":"3gf1-1pt4myH"}},{"cell_type":"code","source":[""],"metadata":{"id":"XZFuC20G5GGN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2번 문제\n","\n","* Kaggle 사이트의 Email spam 데이터 세트입니다. \n","* 강의에서 배운 지도학습 모델들을 모두 적용한 코드가 작성되어있습니다. 각 모델의 정확도를 비교하고 한개의 모델을 선택하여 파라미터를 조정하고 가장 높은 정확도를 도출하는 파라미터 조합을 찾으세요.\n","  * Vectorize\n","    * \n","    ```python\n","    from sklearn.feature_extraction.text import CountVectorizer\n","    count_vectorizer = CountVectorizer() \n","    ```"],"metadata":{"id":"fx0JqvxtxMOr"}},{"cell_type":"markdown","source":["# Email spam dataset\n","\n","**Content**\n","\n","이 데이터 세트는 일부 메일을 임의로 수집하여 스팸 또는 햄으로 분류하는 데이터 세트입니다. 첫 번째 열에 스팸/햄 클래스.(each one is a column):\n","\n","* v1(class)\n","* v2(text)\n","\n","**Inspiration**\n","\n","이러한 text를 사용하여 label에 따라 Email을 분류할 수 있음."],"metadata":{"id":"GVqsFVcxuEdU"}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"pA7AYPPSuEda"}},{"cell_type":"code","source":["# common lib\n","import sklearn\n","import numpy as np"],"metadata":{"id":"dN4TVGrwuEda"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dataset"],"metadata":{"id":"9TruXH2fuEda"}},{"cell_type":"markdown","source":["### read csv by pandas"],"metadata":{"id":"zFDMmw-TuEdb"}},{"cell_type":"markdown","source":["#### github"],"metadata":{"id":"4F5RAwYX6LLG"}},{"cell_type":"code","source":["import pandas as pd\n","\n","url = 'https://raw.githubusercontent.com/EugeneYoo/practice_file/main/spam.csv'\n","data_email = pd.read_csv(url, encoding=\"ISO-8859-1\")\n","data_email.columns = ['class', 'sms1', 'sms2', 'sms3', 'sms4']\n","data_email.head()"],"metadata":{"id":"NjXumMvd6LLG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Preprocess"],"metadata":{"id":"8902TQIKuEdc"}},{"cell_type":"markdown","source":["### Split to data, target\n","\n"],"metadata":{"id":"morZQkM9uEdd"}},{"cell_type":"code","source":["target_name = 'class'\n","\n","email_X_raw = data_email.drop([target_name],axis = 1) \n","email_y_raw = data_email[target_name].values.reshape(-1,1)"],"metadata":{"id":"ZymK5ignuEdd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Missing value deletion"],"metadata":{"id":"28OMFQrvxC0p"}},{"cell_type":"code","source":["email_X = email_X_raw.drop(['sms2','sms3','sms4'],axis = 1).values.ravel().tolist()"],"metadata":{"id":"T8F0aJgpxOAS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ordinal encoding"],"metadata":{"id":"LkpITf1a1lUK"}},{"cell_type":"code","source":["from sklearn.preprocessing import OrdinalEncoder\n","ordinal_encoder = OrdinalEncoder()\n","email_y = ordinal_encoder.fit_transform(email_y_raw).ravel()\n","email_y[:10]"],"metadata":{"id":"r7sUYi1G1olI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Split to train and test set"],"metadata":{"id":"i6ACbsyWuEdd"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","email_X_train, email_X_test, email_y_train, email_y_test = train_test_split(email_X, email_y, test_size=0.3, random_state=42)"],"metadata":{"id":"Qkg2oR8NuEdd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Vectorization for text data\n","* sklearn.feature_extraction.text.[CountVectorizer()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n","  * 문서를 토큰 리스트로 변환\n","  * 각 문서에서 토큰의 출현 빈도 카운트\n","  * 각 문서를 Bag of words(BOW) 인코딩 벡터로 변환\n"],"metadata":{"id":"jCWGUdWUuEdd"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","count_vectorizer = CountVectorizer() \n","email_X_train_count = count_vectorizer.fit_transform(email_X_train).toarray()\n","email_X_test_count = count_vectorizer.transform(email_X_test).toarray()"],"metadata":{"id":"dTG3W1v0yuja"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dQd-aqEzuEde"},"source":["## Accuracy for each model"]},{"cell_type":"markdown","source":["#### Visualization 함수"],"metadata":{"id":"PqANLoMgyhfP"}},{"cell_type":"code","source":["%matplotlib inline\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","def viz_val_bar(param_range, test_acc, param_name):\n","  idx = np.arange(len(param_range))\n","  plt.figure(figsize=(10,5))\n","  colors = sns.color_palette('hls',len(param_range))\n","  bars = plt.bar(idx, test_acc, width=0.3, color=colors)\n","  plt.xlabel(param_name)\n","  plt.ylabel('Accuracy')\n","  plt.ylim([np.min(test_acc)*0.99, np.max(test_acc)*1.01])\n","  # plt.xticks(idx, param_range, fontsize=15, rotation=30)\n","  plt.legend(handles=bars, labels=param_range)\n","  plt.show()"],"metadata":{"id":"DvNqz99FyhfZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","\n","clf1 = KNeighborsClassifier()\n","clf2 = GaussianNB()\n","clf3 = MultinomialNB()\n","clf4 = BernoulliNB()\n","clf5 = LogisticRegression()\n","clf6 = DecisionTreeClassifier(random_state=1)\n","clf7 = RandomForestClassifier(random_state=1)\n","\n","from sklearn.metrics import accuracy_score\n","\n","clfs = [clf1, clf2, clf3, clf4, clf5, clf6, clf7]\n","\n","raw_accs = []\n","class_names = []\n","for clf in clfs:\n","  clf.fit(email_X_train_count, email_y_train)\n","  pred = clf.predict(email_X_test_count)\n","  class_name = clf.__class__.__name__\n","  class_names.append(class_name)\n","  raw_acc = accuracy_score(email_y_test, pred)\n","  raw_accs.append(raw_acc)\n","  print('{0} 정확도: {1:.4f}'.format(class_name, raw_acc))\n","\n","viz_val_bar(class_names, raw_accs, 'models')"],"metadata":{"id":"UoBTUvxUytff"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Visualization 함수"],"metadata":{"id":"v7ujMqccToNZ"}},{"cell_type":"code","source":["%matplotlib inline\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","\n","# 수치형 파라미터 시각화 함수\n","def viz_val_curve(param_range, train_mean, train_std, test_mean, test_std, param_name, xscale_log=False):\n","  plt.plot(param_range, train_mean, \n","          color='blue', marker='o', \n","          markersize=5, label='Training accuracy')\n","\n","  plt.fill_between(param_range, train_mean + train_std,\n","                  train_mean - train_std, alpha=0.15,\n","                  color='blue')\n","\n","  plt.plot(param_range, test_mean, \n","          color='green', linestyle='--', \n","          marker='s', markersize=5, \n","          label='Validation accuracy')\n","\n","  plt.fill_between(param_range, \n","                  test_mean + test_std,\n","                  test_mean - test_std, \n","                  alpha=0.15, color='green')\n","\n","\n","  plt.grid()\n","  plt.legend(loc='lower right')\n","  if xscale_log:\n","    plt.xscale('log')\n","  plt.xlabel(param_name)\n","  plt.ylabel('Accuracy')\n","  plt.ylim([np.min(test_mean)*0.8, np.max(train_mean)*1.2])\n","  plt.tight_layout()\n","  plt.show()\n","\n","# 범주형 파라미터 시각화 함수\n","def viz_val_bar(param_range, train_mean, train_std, test_mean, test_std, param_name):\n","  idx = np.arange(len(param_range))\n","  plt.bar(idx, test_mean, width=0.3)\n","  plt.xlabel(param_name)\n","  plt.ylabel('Accuracy')\n","  plt.ylim([np.min(test_mean)*0.9, np.max(test_mean)*1.1])\n","  plt.xticks(idx, param_range, fontsize=15)\n","  plt.show()"],"metadata":{"id":"Wn8UJ628ToNZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**<font color='red'>정확도가 높게 나타나는 모델 1개를 선택하고 파라미터를 조정하여 더 높은 정확도를 도출하시오.</font>**"],"metadata":{"id":"bHE_GnPW5YRC"}},{"cell_type":"code","source":[""],"metadata":{"id":"IOvJyv6_5YRD"},"execution_count":null,"outputs":[]}]}